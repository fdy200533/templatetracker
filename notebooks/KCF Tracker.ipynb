{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "from numpy.fft import fft2, ifft2, ifftshift, fftshift\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from menpo.image import Image\n",
    "from menpo.shape import PointCloud\n",
    "from menpo.feature import no_op, hog \n",
    "from menpo.visualize import visualize_images\n",
    "\n",
    "from templatetracker.correlationfilter.base import (\n",
    "    KCFTracker, compute_max_peak, compute_meanshift_peak)\n",
    "from templatetracker.correlationfilter.kernelizedfilter import learn_kcf\n",
    "from templatetracker.correlationfilter.utils import (\n",
    "    generate_bounding_box, build_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def greyscale(i):\n",
    "    return i.as_greyscale('average')\n",
    "\n",
    "def greyscale_hog(i):\n",
    "    return hog(greyscale(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel Correlation Filter (CF) based Tracker "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tracker is a first initial implementation of the ideas describes in the following 3 papers regarding template tracking using adaptive correlation filters:\n",
    "\n",
    "- David S. Bolme, J. Ross Beveridge,  Bruce A. Draper and Yui Man Lui. \"Visual Object Tracking using Adaptive Correlation Filters\". CVPR, 2010\n",
    "- Hamed Kiani Galoogahi, Terence Sim,  Simon Lucey. \"Multi-Channel Correlation Filters\". ICCV, 2013.\n",
    "- J. F. Henriques, R. Caseiro, P. Martins, J. Batista. \"High-Speed Tracking with Kernelized Correlation Filters\". TPAMI, 2015."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and manipulate basket ball video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read, pre-process and store a particular number of frames of the provided basket ball video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "video_path = '../data/video.mp4'\n",
    "cam = cv2.VideoCapture(video_path)\n",
    "\n",
    "print 'Is video capture opened?', cam.isOpened()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_frames = 1000\n",
    "resolution = (640, 360)\n",
    "\n",
    "frames = []\n",
    "for _ in range(n_frames):\n",
    "    # read frame\n",
    "    frame = cam.read()[1]\n",
    "    # scale down\n",
    "    frame = cv2.resize(frame, resolution)\n",
    "    # bgr to rgb\n",
    "    frame = frame[..., ::-1]\n",
    "    # pixel values from 0 to 1\n",
    "    frame = np.require(frame, dtype=np.double)\n",
    "    frame /= 255\n",
    "    # roll channel axis to the front\n",
    "    frame = np.rollaxis(frame, -1)\n",
    "    # build menpo image and turn it to grayscale\n",
    "    frame = Image(frame)\n",
    "    # append to frame list\n",
    "    frames.append(frame)\n",
    "    \n",
    "cam.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "visualize_images(frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the position and size of the target on the first frame. Note that we need to this manually!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# first frame\n",
    "frame0 = frames[0]\n",
    "\n",
    "# manually define target centre\n",
    "target_centre0 = PointCloud(np.array([168.0, 232.0])[None])\n",
    "# manually define target size\n",
    "target_shape = (31.0, 31.0)\n",
    "# build bounding box containing the target\n",
    "target_bb = generate_bounding_box(target_centre0, target_shape)\n",
    "\n",
    "# add target centre and bounding box as frame landmarks\n",
    "frame0.landmarks['target_centre'] = target_centre0\n",
    "frame0.landmarks['target_bb'] = target_bb\n",
    "\n",
    "# visualize initialization\n",
    "frame0.view_widget()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Track basket ball video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and initialize the correlation filter based tracker by giving it the first frame and the target position and size on the first frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set options\n",
    "\n",
    "# specify the kind of filters to be learned and incremented\n",
    "learn_filter = learn_kcf # learn_mosse or learn_mccf\n",
    "\n",
    "# specify image representation used for tracking\n",
    "features = greyscale_hog # no_op, greyscale, greyscale_hog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tracker = KCFTracker(frame0, target_centre0, target_shape, learn_filter=learn_filter, \n",
    "                     features=features, sigma=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the learned correlation filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# only the up to the first 5 channels are shown\n",
    "n_channels = np.minimum(5, tracker.alpha.shape[0])\n",
    "fig_size = (3*n_channels, 3*n_channels)\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.set_size_inches(fig_size)\n",
    "for j, c in enumerate(tracker.alpha[:n_channels]):\n",
    "    plt.subplot(1, n_channels, j+1)\n",
    "    plt.title('KCF in spatial domain')\n",
    "    plt.imshow(tracker.alpha[j])\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.set_size_inches(fig_size)\n",
    "for j, c in enumerate(tracker.alpha[:n_channels]):\n",
    "    plt.subplot(1, n_channels, j+1)\n",
    "    plt.title('KCF in frequency domain')\n",
    "    plt.imshow(np.abs(fftshift(fft2(tracker.alpha[j]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Track the previous frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set options\n",
    "\n",
    "# filter adaptive parameter; values close to 0 give more weight to filters derive from the last tracked frames, \n",
    "# values close to 0 give more weight to the initial filter\n",
    "nu = 0.125\n",
    "\n",
    "# specifies a threshold on the peak to sidelobe measure below which there is to much uncertainty wrt the target \n",
    "# position and concequently filters are not updated based on the current frame\n",
    "psr_threshold = 100\n",
    "\n",
    "# specifies how the next target position is obtained given the filter response\n",
    "compute_peak = compute_max_peak # compute_max_peak or compute_meanshift_peak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target_centre = target_centre0\n",
    "\n",
    "filters = []\n",
    "targets = []\n",
    "psrs = []\n",
    "rs = []\n",
    "for j, frame in enumerate(frames):\n",
    "    # track target\n",
    "    target_centre, psr, r = tracker.track(frame, target_centre, nu=nu,\n",
    "                                          psr_threshold=psr_threshold,\n",
    "                                          compute_peak=compute_peak)\n",
    "    # add target centre and its bounding box as landmarks\n",
    "    frame.landmarks['tracked_centre'] = target_centre\n",
    "    frame.landmarks['tracked_bb'] = generate_bounding_box(target_centre, target_shape)\n",
    "    # add psr to list\n",
    "    psrs.append(psr)\n",
    "    rs.append(r)\n",
    "    \n",
    "#     print j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore tracked frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "visualize_images(frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show peak to sidelobe ratio (PSR) over the entire sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.title('Peak to sidelobe ratio (PSR)')\n",
    "plt.plot(range(len(psrs)), psrs)   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
