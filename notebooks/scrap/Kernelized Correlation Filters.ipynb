{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "from numpy.fft import fft2, ifft2, fftshift, ifftshift\n",
    "\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import menpo.io as mio\n",
    "from menpo.image import Image\n",
    "from menpo.feature import hog, no_op\n",
    "from menpo.shape import PointCloud\n",
    "from menpo.visualize import visualize_images\n",
    "\n",
    "from templatetracker.correlationfilter.kernelizedfilter import (\n",
    "    gaussian_correlation, polynomial_correlation, \n",
    "    linear_correlation, learn_kcf)\n",
    "from templatetracker.correlationfilter.utils import (\n",
    "    build_grid, normalizenorm_vec, fast2dconv, crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def greyscale(i):\n",
    "    return i.as_greyscale('average')\n",
    "\n",
    "def greyscale_hog(i):\n",
    "    return hog(greyscale(i))\n",
    "\n",
    "def combine(i):\n",
    "    return Image(np.concatenate((i.pixels, greyscale(i).pixels, greyscale_hog(i).pixels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernelized Correlation Filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and manipulate data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load landmarked facial images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "images = []\n",
    "for i in mio.import_images('../../data/face_images/*', verbose=True, \n",
    "                           max_images=5):\n",
    "    i.crop_to_landmarks_proportion_inplace(0.5)\n",
    "    i = i.rescale_landmarks_to_diagonal_range(100)\n",
    "    images.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "visualize_images(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract 31 x 31 patches around landmark number 45 (the corner of the left eye) from the previous images. Note that any other landmark could be chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "patch_shape = np.asarray((101, 101))\n",
    "lm_number = 45\n",
    "features = no_op # no_op, gresycale, greyscale_hog\n",
    "\n",
    "image_patches = []\n",
    "pixel_patches = []\n",
    "for i in images:\n",
    "    image_patches.append(i.extract_patches_around_landmarks(patch_size=patch_shape)[lm_number])\n",
    "    feature_patches = features(image_patches[-1])\n",
    "    pixel_patches.append(feature_patches.pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "visualize_images(image_patches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store patches as numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.asarray(pixel_patches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the patches that we will used in order to define and test our Kernelized Correlation Filters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the desired response for each patch. Note that, because all patches are centred about the same landmark they share the same desired response, i.e. a 2 dimensional Gaussian response centred at the middle of the patch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cov = 3\n",
    "\n",
    "# define Gaussian response\n",
    "mvn = multivariate_normal(mean=np.zeros(2), cov=cov)\n",
    "grid = build_grid((31, 31))\n",
    "y = mvn.pdf(grid)[None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.title('Desired response')\n",
    "plt.imshow(y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn Kernelized Correlation Filter (KCF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we will use the first image patch as the template from which to learn a KCF. Note that we could have chosen any other image patch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_number = 0\n",
    "x = X[img_number]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apart from the kernel correlation specific parameters, we need to make some choices regarding the overall learning procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# whether to normalize the image\n",
    "normalize = True\n",
    "# wheter to mask the images with a cosine mask\n",
    "mask = True\n",
    "# regularization parameter\n",
    "l = 0.01\n",
    "# the type of kernel correlation to be used\n",
    "kernel_correlation = gaussian_correlation\n",
    "\n",
    "c1 = np.hanning(patch_shape[0])\n",
    "c2 = np.hanning(patch_shape[1])\n",
    "cosine_mask = c1[..., None].dot(c2[None, ...]) if mask else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use 3 different kernel correlation measures, namely: gaussian, polynomial and linear. Some of them have its own parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if kernel_correlation == gaussian_correlation:\n",
    "    # sigma: gaussian kernel std\n",
    "    kwargs = {'sigma': 0.3}\n",
    "elif kernel_correlation == polynomial_correlation:\n",
    "    # a: polynomial exponent, b: polynomial constant \n",
    "    kwargs = {'a': 10, 'b': 1}\n",
    "elif kernel_correlation == linear_correlation: \n",
    "    # no params\n",
    "    kwargs = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to learn a KCF for the first image patch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_ = normalizenorm_vec(x) if normalize else x\n",
    "x_ = cosine_mask * x_ if mask else x_\n",
    "\n",
    "alpha, x_ = learn_kcf(x_, y, kernel_correlation=kernel_correlation, l=l, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig_size = (6, 6)\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('KCF in spatial domain')\n",
    "plt.imshow(alpha[0])\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('KCF in frequency domain')\n",
    "plt.imshow(np.abs(fftshift(fft2(alpha[0]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test KCF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to test the correctness of the learned KCF we will extract 61 x 61 patches centred around landmark number 42, i.e the right corner of the nose.. Note that we will now expect to get responses whith peaks shifted towards the right hence, correctly localizing the eye corner for which the KCF was learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lm_test = 21\n",
    "\n",
    "patch_shape2 =(91, 91)\n",
    "\n",
    "image_prime_patches = []\n",
    "pixel_prime_patches = []\n",
    "for i in images:\n",
    "    image_prime_patches.append(i.extract_patches_around_landmarks(patch_size=patch_shape2)[lm_test])\n",
    "    feature_prime_patches = features(image_prime_patches[-1])\n",
    "    pixel_prime_patches.append(feature_prime_patches.pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "visualize_images(image_prime_patches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store patches as numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_prime = np.asarray(pixel_prime_patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rs = [] \n",
    "for (z, x) in zip(X_prime, X):\n",
    "    z_ = normalizenorm_vec(z) if normalize else z\n",
    "    x_ = normalizenorm_vec(x) if normalize else x\n",
    "    \n",
    "    # compute kernel correlation between template and image\n",
    "    kxz = kernel_correlation(x_, z_, **kwargs) \n",
    "    # compute kernel correlation response\n",
    "    r = fast2dconv(kxz, alpha)\n",
    "    \n",
    "    rs.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# only up to the first 5 images are shown\n",
    "n_images = np.minimum(5, len(X_prime))\n",
    "fig_size = (3*n_images, 3*n_images)\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.set_size_inches(fig_size)\n",
    "for j, r in enumerate(rs[:n_images]):\n",
    "    plt.subplot(1, n_images, j+1)\n",
    "    plt.title('response')\n",
    "    plt.imshow(r[0])\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.set_size_inches(fig_size)\n",
    "for j, (r, i) in enumerate(zip(rs[:n_images], image_prime_patches[:n_images])):\n",
    "    plt.subplot(1, n_images, j+1)\n",
    "    plt.title('original image')\n",
    "    peak = np.asarray(np.unravel_index(r.argmax(), r.shape))[1:]\n",
    "    i.landmarks['peak'] = PointCloud(peak[None, ...])\n",
    "    i.view_landmarks(marker_face_colour='r', figure_size=fig_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
