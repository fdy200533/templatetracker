{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "from numpy.fft import fft2, ifft2, fftshift, ifftshift\n",
    "\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import menpo.io as mio\n",
    "from menpo.image import Image\n",
    "from menpo.feature import hog, no_op\n",
    "from menpo.shape import PointCloud\n",
    "from menpo.visualize import visualize_images\n",
    "\n",
    "from templatetracker.correlationfilter.correlationfilter import (\n",
    "    learn_mosse, learn_mccf, learn_deep_cf)\n",
    "from templatetracker.correlationfilter.utils import (\n",
    "    build_grid, normalizenorm_vec, fast2dconv, crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def greyscale(i):\n",
    "    return i.as_greyscale('average')\n",
    "\n",
    "def greyscale_hog(i):\n",
    "    return hog(greyscale(i))\n",
    "\n",
    "def combine(i):\n",
    "    return Image(np.concatenate((i.pixels, greyscale(i).pixels, greyscale_hog(i).pixels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernelized Correlation Filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and manipulate data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load landmarked facial images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "images = []\n",
    "for i in mio.import_images('/Users/joan/PhD/DataBases/faces/lfpw/trainset/*', verbose=True, \n",
    "                           max_images=300):\n",
    "    i.crop_to_landmarks_proportion_inplace(0.5)\n",
    "    i = i.rescale_landmarks_to_diagonal_range(100)\n",
    "    images.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "visualize_images(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract 31 x 31 patches around landmark number 45 (the corner of the left eye) from the previous images. Note that any other landmark could be chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "patch_shape = np.asarray((101, 101))\n",
    "lm_number = 45\n",
    "features = greyscale # no_op, gresycale, greyscale_hog\n",
    "\n",
    "image_patches = []\n",
    "pixel_patches = []\n",
    "for i in images:\n",
    "    image_patches.append(i.extract_patches_around_landmarks(patch_size=patch_shape)[lm_number])\n",
    "    feature_patches = features(image_patches[-1])\n",
    "    pixel_patches.append(feature_patches.pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "visualize_images(image_patches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store patches as numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.asarray(pixel_patches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the patches that we will used in order to define and test our Kernelized Correlation Filters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the desired response for each patch. Note that, because all patches are centred about the same landmark they share the same desired response, i.e. a 2 dimensional Gaussian response centred at the middle of the patch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cov = 3\n",
    "\n",
    "# define Gaussian response\n",
    "mvn = multivariate_normal(mean=np.zeros(2), cov=cov)\n",
    "grid = build_grid((31, 31))\n",
    "y = mvn.pdf(grid)[None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.title('Desired response')\n",
    "plt.imshow(y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn Correlation Filter (CF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we will use the first image patch as the template from which to learn a CF. Note that we could have chosen any other image patch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# img_number = 0\n",
    "# x = X[img_number]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apart from the kernel correlation specific parameters, we need to make some choices regarding the overall learning procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# whether to normalize the image\n",
    "normalize = True\n",
    "# wheter to mask the images with a cosine mask\n",
    "mask = True\n",
    "# regularization parameter\n",
    "l = 0.1\n",
    "# type of filter\n",
    "filter_type = 'deep_mosse'\n",
    "# boundary padding\n",
    "boundary = 'symmetric'\n",
    "\n",
    "c1 = np.hanning(patch_shape[0])\n",
    "c2 = np.hanning(patch_shape[1])\n",
    "cosine_mask = c1[..., None].dot(c2[None, ...]) if mask else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to learn a CF for the first image patch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_ = np.empty_like(X)\n",
    "for j, x in enumerate(X):\n",
    "    x_ = normalizenorm_vec(x) if normalize else x\n",
    "    x_ = cosine_mask * x_ if mask else x_\n",
    "    X_[j] = x_\n",
    "\n",
    "if filter_type is 'mosse':\n",
    "    cf, _, _ = learn_mosse(X_, y, l=l, boundary=boundary)\n",
    "elif filter_type is 'mccf':\n",
    "    cf, _, _ = learn_mccf(X_, y, l=l, boundary=boundary)\n",
    "elif filter_type is 'deep_mosse':\n",
    "    cf, _, _ = learn_deep_cf(X_, y, learn_cf=learn_mosse, n_levels=1, l=l, boundary=boundary)\n",
    "elif filter_type is 'deep_mccf':\n",
    "    cf, _, _ = learn_deep_cf(X_, y, learn_cf=learn_mccf, n_levels=3, l=l, boundary=boundary)\n",
    "    \n",
    "cf = cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# only the up to the first 5 channels are shown\n",
    "n_channels = np.minimum(5, cf.shape[0])\n",
    "fig_size = (3*n_channels, 3*n_channels)\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.set_size_inches(fig_size)\n",
    "for j, c in enumerate(cf[:n_channels]):\n",
    "    plt.subplot(1, n_channels, j+1)\n",
    "    plt.title('CF in spatial domain')\n",
    "    plt.imshow(cf[j])\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.set_size_inches(fig_size)\n",
    "for j, c in enumerate(cf[:n_channels]):\n",
    "    plt.subplot(1, n_channels, j+1)\n",
    "    plt.title('CF in frequency domain')\n",
    "    plt.imshow(np.abs(fftshift(fft2(cf[j]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test KCF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to test the correctness of the learned KCF we will extract 61 x 61 patches centred around landmark number 31, i.e the right corner of the nose. Note that we will now expect to get responses whith peaks shifted towards the right hence, correctly localizing the eye corner for which the KCF was learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lm_test = 42\n",
    "\n",
    "patch_shape2 =(81, 81)\n",
    "\n",
    "image_prime_patches = []\n",
    "pixel_prime_patches = []\n",
    "for i in images:\n",
    "    image_prime_patches.append(i.extract_patches_around_landmarks(patch_size=patch_shape2)[lm_test])\n",
    "    feature_prime_patches = features(image_prime_patches[-1])\n",
    "    pixel_prime_patches.append(feature_prime_patches.pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "visualize_images(image_prime_patches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store patches as numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_prime = np.asarray(pixel_prime_patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rs = [] \n",
    "for z in X_prime:\n",
    "    z_ = normalizenorm_vec(z) if normalize else z\n",
    "    cf_ = normalizenorm_vec(cf) if normalize else cf\n",
    "    # compute correlation response\n",
    "    r = np.sum(fast2dconv(z_, cf, boundary=boundary), axis=0)[None]\n",
    "    rs.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# only up to the first 5 images are shown\n",
    "n_images = np.minimum(5, len(X_prime))\n",
    "fig_size = (3*n_images, 3*n_images)\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.set_size_inches(fig_size)\n",
    "for j, r in enumerate(rs[:n_images]):\n",
    "    plt.subplot(1, n_images, j+1)\n",
    "    plt.title('response')\n",
    "    plt.imshow(r[0])\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.set_size_inches(fig_size)\n",
    "for j, (r, i) in enumerate(zip(rs[:n_images], image_prime_patches[:n_images])):\n",
    "    plt.subplot(1, n_images, j+1)\n",
    "    plt.title('original image')\n",
    "    peak = np.asarray(np.unravel_index(r.argmax(), r.shape))[1:]\n",
    "    i.landmarks['peak'] = PointCloud(peak[None, ...])\n",
    "    i.view_landmarks(marker_face_colour='r', figure_size=fig_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
